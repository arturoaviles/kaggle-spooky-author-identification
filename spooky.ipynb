{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/arturoaviles/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\"\"\" There are many features to determine if a text is from an author, for example:\n",
    "\n",
    "- Word Frecuency\n",
    "- Vocabulary Richness\n",
    "- Verb C\n",
    "- N-Grams\n",
    "- etc.\n",
    "\n",
    "In this case, I will use Word Frecuency\n",
    "\"\"\"\n",
    "\n",
    "# 1st, I will check the available data. This data contains the texts with their respective Author. \n",
    "texts_with_author = pd.read_csv(\"data/train.csv\")\n",
    "texts_with_author.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EAP</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPL</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MWS</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                               text\n",
       "0    EAP  This process, however, afforded me no means of...\n",
       "1    HPL  It never once occurred to me that the fumbling...\n",
       "2    MWS  How lovely is spring As we looked from Windsor..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ids are not important, we need to group and join all the texts by author\n",
    "# The stop words inside this texts will help beacuse we are not trying to understand the intetion of the author.\n",
    "# Every person uses this stop words with more or less frecuency than others.\n",
    "texts_groupby_author = texts_with_author.groupby(\"author\")[\"text\"].apply(' '.join).reset_index()\n",
    "\n",
    "texts_groupby_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EAP</td>\n",
       "      <td>this process, however, afforded me no means of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                               text\n",
       "0    EAP  this process, however, afforded me no means of...\n",
       "1    HPL  it never once occurred to me that the fumbling...\n",
       "2    MWS  how lovely is spring as we looked from windsor..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We transform every text to lowercase to eliminate the tokenization of same words with capitalized letters.\n",
    "texts_groupby_author[\"text\"] = texts_groupby_author.text.str.lower()\n",
    "\n",
    "texts_groupby_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use a dict to save the word frequencies for each author\n",
    "word_frequencies_by_author = {}\n",
    "\n",
    "for _, row in texts_groupby_author.iterrows():\n",
    "    author = row[\"author\"]\n",
    "    text = row[\"text\"]\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    frequency = nltk.FreqDist(tokens)\n",
    "    word_frequencies_by_author[author] = frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2824342312149186 EAP\n",
      "0.23157307827166596 HPL\n",
      "0.27968435547081877 MWS\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Still, as I urged our leaving Ireland with such inquietude and impatience, my father thought it best to yield.\"\n",
    "sentence = sentence.lower()\n",
    "sentence_tokens = nltk.tokenize.word_tokenize(sentence)\n",
    "\n",
    "for author in word_frequencies_by_author.keys():\n",
    "    total = 0\n",
    "    for word in sentence_tokens:\n",
    "        total += word_frequencies_by_author[author].freq(word) \n",
    "    print(total, author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>frequency</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [author, frequency, sentence]\n",
       "Index: []"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe to save the data\n",
    "dataframe_with_frequencies = pd.DataFrame(columns=('author', 'frequency', 'sentence'))\n",
    "dataframe_with_frequencies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the test file and iterate on it\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "for iter_num, row in test.iterrows():\n",
    "    sentence = row[\"text\"] # Get sentence\n",
    "    sentence = sentence.lower() # Str to lower\n",
    "    sentence_tokens = nltk.tokenize.word_tokenize(sentence) # Tokenize test words\n",
    "    \n",
    "    # Get the author and probability of authorship attribution\n",
    "    best_frequency_author = \"\"\n",
    "    best_frequency_by_author = 0\n",
    "    for author in word_frequencies_by_author.keys():\n",
    "        total = 0\n",
    "        for word in sentence_tokens:\n",
    "            total += word_frequencies_by_author[author].freq(word) \n",
    "        #print(total, author)\n",
    "        if(total > best_frequency_by_author):\n",
    "            best_frequency_author = author\n",
    "            best_frequency_by_author = total\n",
    "        \n",
    "    # Add a new row to the dataframe\n",
    "    dataframe_with_frequencies.loc[iter_num+1] = [best_frequency_author, best_frequency_by_author, sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_with_frequencies.head()\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "dataframe_with_frequencies.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
